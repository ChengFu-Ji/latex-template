\section{相關研究}
本研究建構一個在Apache Spark 叢集上的Veracity真實度模型，且應用於串流XML的真實度計算。而XML具有樹狀結構的特性，所以在分散式系統處理XML的時候，如何切割文件，但依然保有XML文件樹狀結構和父子節點的關係，以及在Hadoop或是Apache Spark的分散式架構下做XML的Query。本章節將就有關這些議題的文獻來做討論。
\subsection{XML文件樹狀結構的關係}
在XML文件當中，我們可以將其轉化成一個樹狀結構，如圖\ref{documenttree}。而這樣的樹狀結構可以告訴我們這一份文件的每一個節點之間父節點與子節點的關係，而大型的XML文件，其結構複雜度讓我們很難去對此文件做query或是將父節點和子節點的關係表示出來，所以有學者提出了DataGuides\cite{dataguides}\cite{oem}的概念，所謂的DataGuides是可以將XML的樹狀結構做萃取，萃取出來的為最簡的結構，DataGuides的演算法如Algorithm 1.\\\par

使用這樣的結構來處理XML文件，可以將效率提高，並且還能完整保留XML樹狀結構中父節點與子節點的關係，如圖\ref{dataguides}所示。\\\par
藉由這樣的萃取，我們可以將大型XML的結構精簡化，減少了所需走訪的節點數，且完整的保留文件的結構訊息。

\begin{figure}[h]
\graphicspath{{/Users/FUDA/Documents/masterThesis/image/}}
\centering
\includegraphics[scale = 0.3]{documenttree.png}
\caption{XML文件樹狀結構}
\label{documenttree}
\end{figure}

\begin{figure}[h]
\graphicspath{{/Users/FUDA/Documents/masterThesis/image/}}
\centering
\includegraphics[scale = 0.3]{dataguide.png}
\caption{DataGuides 萃取後的結構}
\label{dataguides}
\end{figure}

\begin{algorithm}
\caption{Dataguides}
\label{alg1}
\renewcommand{\algorithmicrequire}{\textbf{Input}}
\renewcommand{\algorithmicensure}{\textbf{Output}}
\begin{algorithmic}
\Require node of XML file
\Ensure JSON of Dataguides tree
\Procedure{dataguides}{$node, guide, position$}
\If{$node = None$}
\State $return$
\EndIf

\If{$node.nodeType = node.ELEMENT\_NODE$}
\State $tag = node.nodeName$
\State $children = node.childNodes$
\State $i = children.length - 1$
\For{each $x \in children$}
\If{$x.nodeType = x.ELEMENT\_NODE$}
nodeSet[x.nodeName] = ' '
\EndIf
\EndFor
\State $Dataguides\ Tree[node.nodeName] = nodeSet$
\While{$i\geq 0 and node.childNodes[i].nodeName \neq tag$}
\State $i = i-1$
\EndWhile
\If{$i = 1$}
\State $newGuidesNode = guide.createElement(tag)$
\State $nextPosition = newGuidesNode$
\Else
\State $nextPosttion = nodechildNodes.item(i)$
\EndIf
\EndIf
\State $dataguides(node.firstChils, guide, nextPosition)$
\State $dataguides(node.nextSibling, guide, position)$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{大型XML文件的平行化處理}
Hongjie et al.的文獻\cite{fan2018handling}提到將大型XML切割成小型的樹狀結構，存進分散式檔案系統，等到使用者的query進來之後，再將切割好的資料提取出來，使用MapReduce進行查詢。利用Hadoop的分散式系統，來到平行化query。文獻當中使用分散式檔案系統儲存XML 文件，也就是說文件在儲存之前需要經過切割。文章當中他們是採用自己設計的切割演算法，將大型XML 文件的樹狀結構切割成小型樹狀結構，接著在使用者的query進入的時候，會平行化的對這一些切割出來的小型樹狀結構作查詢。\\\par
這裡面有幾個問題點，第一點是當有多個XML文件的時候，每一份文件都會切割演算法做切割並且儲存，這時候會產生很多小文件，如何對應切割出來的小文件與原始大文件的關係，這會影響到要對哪一個文件進行處理，而文件切割和對應的部分，在曾偉誠學者的論文\cite{eiffcientXML}當中有提到，一般在Hadoop當中，透過MapReduce切割XML文件的時候，開始標籤(<tag>)與結束標籤(</tag>)之間的關係會被切割到不同的部分，導致XML文件的節點關係不清楚，第二點是文件切割與平行化的問題，在前面有提到Hadoop是以前大家常使用的大數據處理引擎。而我們如何計算和得知切割XML的個數與平行化任務的數量各為多少是比較好的，這是在做平行化運算要面臨的問題點。\\\par

我們可以看到圖\ref{xmlhadoop}右半邊的即為XML文件切割完之後要進行平行化運算的部分。當中我們比較關注的是XML文件怎麼切割？被切割了幾份？以及平行畫的時候會產生的任務數量以及計算量，都是我們要考量的問題。

\begin{figure}[h]
\graphicspath{{/Users/FUDA/Documents/masterThesis/image/}}
\includegraphics[scale=0.3]{xmlHadoop.png}
\caption{XML在Hadoop的切割與平行化}
\label{xmlhadoop}
\end{figure}

\subsection{文件相似度}
在本研究所提出的Veraicty之問題，其實也就是文件相似的問題。在一般的研究當中會使用幾種相似度比較法，如編輯距離(Edit distance)、漢明距離等。
\newpage